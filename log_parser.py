import re
import json
import os
import difflib
from collections import defaultdict

# ==============================================================================
# 1. Log Reader (ë…¸ì´ì¦ˆ í•„í„°ë§)
# ==============================================================================
class SubutaiLogReader:
    def __init__(self, file_path):
        self.file_path = file_path

    def _is_ignorable(self, line_num, line):
        """
        [User Custom Logic] ë¶„ì„í•  ê°€ì¹˜ê°€ ì—†ëŠ” ë¼ì¸ì„ Trueë¡œ ë¦¬í„´
        """
        stripped = line.strip()
        if not stripped: return True
        if stripped.startswith("---") or stripped.startswith("==="): return True
        if stripped.startswith("Info:") or "Page" in stripped: return True
        return False

    def stream_valid_lines(self):
        if not os.path.exists(self.file_path):
            return []
        with open(self.file_path, 'r', encoding='utf-8', errors='ignore') as f:
            for i, line in enumerate(f, 1):
                if not self._is_ignorable(i, line):
                    yield line.strip()

# ==============================================================================
# 2. Parser (N-Tuple ì¶”ì¶œ)
# ==============================================================================
class SubutaiParser:
    def __init__(self):
        # ì˜ˆ: LINT-01, TIM-05
        self.rule_pattern = re.compile(r"^([A-Z]+-\d+)")
        # ë”°ì˜´í‘œ ì•ˆì˜ ë³€ìˆ˜ ì¶”ì¶œ
        self.var_pattern = re.compile(r"['\"](.*?)['\"]")

    def parse_line(self, line):
        match = self.rule_pattern.search(line)
        rule_id = match.group(1) if match else "UNKNOWN"
        
        variables = self.var_pattern.findall(line)
        var_tuple = tuple(variables) if variables else ("NO_VAR",)
        
        # ë¼ˆëŒ€ë§Œ ë‚¨ê¸°ê¸° (ìˆ«ìì™€ ë³€ìˆ˜ ë‚´ìš© ì œê±°)
        template = self.var_pattern.sub("'<VAR>'", line)
        template = re.sub(r"\d+", "<NUM>", template)
        
        return {
            "rule_id": rule_id,
            "template": template,
            "variables": var_tuple,
            "raw_log": line
        }

# ==============================================================================
# 3. Aggressive Clusterer (ê²½ë¡œ ì¼ë°˜í™” í•µì‹¬ ì—”ì§„)
# ==============================================================================
class AggressiveClusterer:
    def __init__(self):
        pass

    def generalize_pattern(self, str1, str2):
        """
        ë‘ ë¬¸ìì—´(ë³€ìˆ˜ëª…/ê²½ë¡œ)ì„ ë¹„êµí•˜ì—¬ 'ë‹¤ë¥¸ ë¶€ë¶„'ë§Œ '*'ë¡œ ì¹˜í™˜í•œ íŒ¨í„´ ë°˜í™˜
        Ex) 'u_cpu_core' + 'u_gpu_core' -> 'u_*_core'
        """
        # 1. ê¸¸ì´ ì°¨ì´ê°€ ë„ˆë¬´ í¬ë©´ êµ¬ì¡°ê°€ ë‹¤ë¥¸ ê²ƒì„ -> ë³‘í•© ì•ˆ í•¨
        if abs(len(str1) - len(str2)) > 10: 
            return None

        # 2. êµ¬ë¶„ì(Delimiter) ê¸°ì¤€ìœ¼ë¡œ í† í°í™”
        # ê²½ë¡œ(/), ì–¸ë”ë°”(_), ì (.) ë“±ì„ ê¸°ì¤€ìœ¼ë¡œ ìª¼ê°¬
        seps = r"([/_.\-])"
        parts1 = re.split(seps, str1)
        parts2 = re.split(seps, str2)

        # êµ¬ì¡°ì  ê¸¸ì´(í† í° ìˆ˜)ê°€ ë‹¤ë¥´ë©´ ë³‘í•© ë¶ˆê°€
        if len(parts1) != len(parts2):
            return None

        new_parts = []
        diff_count = 0
        
        for p1, p2 in zip(parts1, parts2):
            if p1 == p2:
                new_parts.append(p1)
            elif '*' in p1: # ì´ë¯¸ ì™€ì¼ë“œì¹´ë“œê°€ ìˆëŠ” ê²½ìš° ìœ ì§€
                new_parts.append(p1)
            else:
                # ë‹¤ë¥´ë‹¤ë©´ '*'ë¡œ ì¹˜í™˜
                diff_count += 1
                new_parts.append("*")
        
        # 3. ì•ˆì „ì¥ì¹˜: ì „ì²´ í† í° ì¤‘ 40% ì´ìƒì´ ë‹¤ë¥´ë©´ "ë„ˆë¬´ ë‹¤ë¥´ë‹¤"ê³  íŒë‹¨í•˜ì—¬ ë³‘í•© ê±°ë¶€
        # (ë„ˆë¬´ ë­‰ëš±ê·¸ë ¤ì§€ëŠ” ê²ƒ ë°©ì§€)
        total_tokens = len(parts1)
        if diff_count > max(1, total_tokens * 0.4):
            return None
            
        return "".join(new_parts)

    def run(self, parsed_logs):
        # Step 1: Template Grouping (ë¬¼ë¦¬ì  1ì°¨ ë¶„ë¥˜)
        template_groups = defaultdict(list)
        for p in parsed_logs:
            # Rule IDì™€ í…œí”Œë¦¿ì´ ê°™ì€ ê²ƒë¼ë¦¬ ëª¨ìŒ
            key = (p['rule_id'], p['template'])
            # ì—¬ê¸°ì„œëŠ” í¸ì˜ìƒ ì²« ë²ˆì§¸ ë³€ìˆ˜(variables[0])ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë§
            if p['variables'] and p['variables'][0] != "NO_VAR":
                template_groups[key].append(p['variables'][0])

        final_results = []

        # Step 2: Iterative Aggressive Merge
        for (rule_id, template), var_list in template_groups.items():
            
            # [í•µì‹¬] ì •ë ¬ì„ í•´ì•¼ ë¹„ìŠ·í•œ ê²ƒë¼ë¦¬ ë¶™ì–´ì„œ ë³‘í•© í™•ë¥ ì´ ë†’ì•„ì§
            var_list.sort()
            
            merged_groups = []
            if not var_list: continue

            # ì²« ë²ˆì§¸ ìš”ì†Œë¥¼ ì‹œì‘ íŒ¨í„´ìœ¼ë¡œ ì¡ìŒ
            current_pattern = var_list[0]
            current_count = 1
            sample_members = [var_list[0]]

            for i in range(1, len(var_list)):
                next_var = var_list[i]
                
                # í˜„ì¬ íŒ¨í„´ê³¼ ë‹¤ìŒ ë³€ìˆ˜ë¥¼ ì¼ë°˜í™” ì‹œë„
                generalized = self.generalize_pattern(current_pattern, next_var)
                
                if generalized:
                    # ë³‘í•© ì„±ê³µ! íŒ¨í„´ ì—…ë°ì´íŠ¸ (êµ¬ì²´ì  -> ì¼ë°˜ì )
                    current_pattern = generalized
                    current_count += 1
                    if len(sample_members) < 3: sample_members.append(next_var)
                else:
                    # ë³‘í•© ì‹¤íŒ¨! ì§€ê¸ˆê¹Œì§€ ë­‰ì¹œ ê·¸ë£¹ ì €ì¥í•˜ê³  ìƒˆë¡œ ì‹œì‘
                    merged_groups.append({
                        "pattern": current_pattern,
                        "count": current_count,
                        "samples": sample_members
                    })
                    current_pattern = next_var
                    current_count = 1
                    sample_members = [next_var]
            
            # ë£¨í”„ ëë‚˜ê³  ë‚¨ì€ ë§ˆì§€ë§‰ ê·¸ë£¹ ì €ì¥
            merged_groups.append({
                "pattern": current_pattern,
                "count": current_count,
                "samples": sample_members
            })

            # ê²°ê³¼ í¬ë§·íŒ…
            for mg in merged_groups:
                # ì¹´í…Œê³ ë¦¬ íƒœê¹…
                if "*" in mg['pattern']:
                    cat = "Grouped Pattern (Waive Check)"
                else:
                    cat = "Single Issue (Fix Check)"

                final_results.append({
                    "rule_id": rule_id,
                    "final_pattern": mg['pattern'],
                    "count": mg['count'],
                    "category": cat,
                    "template": template,
                    "example_vars": mg['samples']
                })

        return final_results

# ==============================================================================
# 4. Main Execution (Test)
# ==============================================================================
if __name__ == "__main__":
    # --- í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ íŒŒì¼ ìƒì„± (ë³µì¡í•œ ê²½ë¡œ í¬í•¨) ---
    dummy_file = "aggressive_test.log"

    print("ğŸš€ Running Aggressive Clustering...\n")

    # 1. Read
    reader = SubutaiLogReader(dummy_file)
    lines = list(reader.stream_valid_lines())
    
    # 2. Parse
    parser = SubutaiParser()
    parsed_data = [parser.parse_line(line) for line in lines]
    
    # 3. Cluster (Aggressive)
    clusterer = AggressiveClusterer()
    results = clusterer.run(parsed_data)
    
    # 4. Result
    print(json.dumps(results, indent=2))

