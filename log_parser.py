import re
import json
import os
from collections import defaultdict

# ==============================================================================
# 1. Log Reader Module (íŒŒì¼ ì½ê¸° ë° í•„í„°ë§)
# ==============================================================================
class SubutaiLogReader:
    def __init__(self, file_path):
        self.file_path = file_path

    def _is_ignorable(self, line_num, line):
        """
        [USER TODO] ë¬´ì‹œí•  ë¼ì¸(Noise)ì„ ê²°ì •í•˜ëŠ” í•„í„° ë¡œì§
        True ë¦¬í„´ ì‹œ í•´ë‹¹ ë¼ì¸ì€ ë¶„ì„ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.
        """
        stripped = line.strip()

        # 1. ë¹ˆ ì¤„ ë¬´ì‹œ
        if not stripped:
            return True
        
        # 2. êµ¬ë¶„ì„  ë¬´ì‹œ
        if stripped.startswith("---") or stripped.startswith("==="):
            return True
        
        # 3. ë‹¨ìˆœ ì •ë³´ì„± ë©”ì‹œì§€ (Info) ë¬´ì‹œ
        # ì˜ˆ: "Info: SpyGlass Version 1.0..."
        if stripped.startswith("Info:") and "Version" in stripped:
            return True

        # 4. í˜ì´ì§€ ë²ˆí˜¸ ë¬´ì‹œ
        if "Page" in stripped and "of" in stripped:
            return True

        return False

    def stream_valid_lines(self):
        """ì œë„ˆë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë©”ëª¨ë¦¬ íš¨ìœ¨ì ìœ¼ë¡œ ìœ íš¨ ë¼ì¸ë§Œ ë°˜í™˜"""
        if not os.path.exists(self.file_path):
            raise FileNotFoundError(f"File not found: {self.file_path}")

        with open(self.file_path, 'r', encoding='utf-8', errors='ignore') as f:
            for i, line in enumerate(f, 1):
                if self._is_ignorable(i, line):
                    continue
                yield line.strip()

# ==============================================================================
# 2. Parser Module (êµ¬ì¡° ë¶„í•´)
# ==============================================================================
class SubutaiParser:
    def __init__(self):
        # Rule ID íŒ¨í„´ (ì˜ˆ: LINT-05, TIM-01)
        self.rule_pattern = re.compile(r"^([A-Z]+-\d+)")
        # ë³€ìˆ˜ ì¶”ì¶œ íŒ¨í„´ (ë”°ì˜´í‘œ ì•ˆì˜ ë‚´ìš©)
        self.var_pattern = re.compile(r"['\"](.*?)['\"]")

    def parse_line(self, line):
        # 1. Rule ID ì¶”ì¶œ
        match = self.rule_pattern.search(line)
        rule_id = match.group(1) if match else "UNKNOWN"
        
        # 2. ë³€ìˆ˜ íŠœí”Œ ì¶”ì¶œ (N-Tuple)
        variables = self.var_pattern.findall(line)
        var_tuple = tuple(variables) if variables else ("NO_VAR",)
        
        # 3. ë¼ˆëŒ€(Template) ìƒì„± (ë³€ìˆ˜ -> <VAR>, ìˆ«ì -> <NUM>)
        # ì˜ˆ: Signal 'A' is 1 -> Signal '<VAR>' is <NUM>
        template = self.var_pattern.sub("'<VAR>'", line)
        template = re.sub(r"\d+", "<NUM>", template)
        
        return {
            "rule_id": rule_id,
            "template": template,
            "variables": var_tuple,
            "raw_log": line
        }

# ==============================================================================
# 3. Clusterer Module (í•µì‹¬ ë¡œì§ ì—”ì§„)
# ==============================================================================
class SubutaiClusterer:
    def __init__(self):
        pass

    def _check_token_similarity(self, str1, str2):
        """[Logic Option] í† í° ìì¹´ë“œ ìœ ì‚¬ë„ ê³„ì‚° (ì¤‘ê°„ì´ ë‹¤ë¥¼ ë•Œ ì‚¬ìš©)"""
        tokens1 = set(str1.split('_'))
        tokens2 = set(str2.split('_'))
        
        # í•©ì§‘í•©ì´ 0ì´ë©´(ì™„ì „ ë‹¤ë¦„) 0 ë¦¬í„´
        if not tokens1 or not tokens2: 
            return False

        intersection = len(tokens1.intersection(tokens2))
        union = len(tokens1.union(tokens2))
        
        score = intersection / union if union > 0 else 0.0
        
        # ìœ ì‚¬ë„ê°€ 60% ì´ìƒì´ë©´ ê°™ì€ ê·¸ë£¹ìœ¼ë¡œ ê°„ì£¼
        return score >= 0.6

    def analyze_numeric_distribution(self, var_list):
        """[Phase 2] ìˆ«ì ë¶„í¬ ë° ë¬¸ìì—´ ìœ ì‚¬ë„ ë¶„ì„"""
        
        # 1. ìˆ«ìë¥¼ ë§ˆìŠ¤í‚¹í•˜ì—¬ ì„ì‹œ ê·¸ë£¹í•‘
        masked_map = defaultdict(list)
        for v in var_list:
            # u_cpu_0 -> u_cpu_*
            # axi_read -> axi_read (ë³€í™” ì—†ìŒ)
            masked = re.sub(r"\d+", "*", v)
            masked_map[masked].append(v)
            
        final_sub_groups = []

        # 2. ê° ë§ˆìŠ¤í‚¹ ê·¸ë£¹ë³„ íŒë‹¨
        for pattern, members in masked_map.items():
            
            # Case A: ìˆ«ìê°€ í¬í•¨ëœ íŒ¨í„´ (ì˜ˆ: u_cpu_*)
            if "*" in pattern:
                if len(members) > 1:
                    # ë©¤ë²„ê°€ ì—¬ëŸ¬ ê°œ -> Bus Error -> Waive Candidate
                    final_sub_groups.append({
                        "pattern": pattern,
                        "count": len(members),
                        "type": "Bus Error (Waive)",
                        "members": members[:3] # ìƒ˜í”Œ
                    })
                else:
                    # ë©¤ë²„ê°€ 1ê°œ -> Pinpoint Error -> Fix Candidate
                    # íŒ¨í„´ì„ '*' ëŒ€ì‹  ì›ë³¸(u_cpu_0)ìœ¼ë¡œ ë³µêµ¬
                    final_sub_groups.append({
                        "pattern": members[0],
                        "count": 1,
                        "type": "Pinpoint (Fix)",
                        "members": members
                    })
            
            # Case B: ìˆ«ìê°€ ì—†ëŠ” ë¬¸ìì—´ íŒ¨í„´ (ì˜ˆ: axi_read)
            else:
                # [Phase 3] ì—¬ê¸°ì„œ Semantic Check ìˆ˜í–‰
                # ë§Œì•½ ë¦¬ìŠ¤íŠ¸ì— ì´ë¯¸ ë¹„ìŠ·í•œ í˜•ì œ(axi_write)ê°€ ìˆë‹¤ë©´ í•©ì¹  ìˆ˜ë„ ìˆìŒ
                # (ê°„ì†Œí™”ë¥¼ ìœ„í•´ ì—¬ê¸°ì„œëŠ” ê°œë³„ ë“±ë¡ í›„, í›„ì²˜ë¦¬ë¡œ ë³‘í•© ê°€ëŠ¥ì„±ì„ ì—´ì–´ë‘ )
                final_sub_groups.append({
                    "pattern": pattern,
                    "count": len(members),
                    "type": "Semantic Check Needed",
                    "members": members[:3]
                })

        return final_sub_groups

    def run(self, parsed_logs):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        
        # Step 1: Template Grouping (ë¬¼ë¦¬ì  1ì°¨ ë¶„ë¥˜)
        template_groups = defaultdict(list)
        for p in parsed_logs:
            key = (p['rule_id'], p['template'])
            template_groups[key].append(p['variables'])

        final_results = []

        # Step 2: ì„¸ë¶€ ë¶„ì„
        for (rule_id, template), var_tuples in template_groups.items():
            
            # N-Tuple ì¤‘ 'ì²« ë²ˆì§¸ ë³€ìˆ˜'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ íŒ¨í„´ ë¶„ì„ (Primary Key)
            # (í•„ìš” ì‹œ ë‘ ë²ˆì§¸ ë³€ìˆ˜ë„ ë£¨í”„ ëŒë©° ë¶„ì„ ê°€ëŠ¥)
            first_vars = [t[0] for t in var_tuples]
            
            analyzed_groups = self.analyze_numeric_distribution(first_vars)
            
            for group in analyzed_groups:
                # ìµœì¢… ê²°ê³¼ ì¡°ë¦½
                final_results.append({
                    "rule_id": rule_id,
                    "pattern": group['pattern'],
                    "count": group['count'],
                    "category": group['type'],
                    "template_hash": hash(template), # DB Keyìš©
                    "sample_logs": [
                        f"{rule_id}: ... {group['members'][0]} ..." 
                    ]
                })

        return final_results

# ==============================================================================
# 4. Main Execution (Orchestrator)
# ==============================================================================
if __name__ == "__main__":
    # --- 0. í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ íŒŒì¼ ìƒì„± ---
    dummy_file = "test_run.log"
    with open(dummy_file, "w") as f:
        f.write("Info: SpyGlass Version 1.0 Start\n")
        f.write("--------------------------------\n")
        # Case 1: Bus Error (Waive ëŒ€ìƒ)
        f.write("LINT-01: Signal 'u_cpu_data_0' is floating\n")
        f.write("LINT-01: Signal 'u_cpu_data_1' is floating\n")
        f.write("LINT-01: Signal 'u_cpu_data_2' is floating\n")
        # Case 2: Pinpoint Error (Fix ëŒ€ìƒ)
        f.write("LINT-01: Signal 'u_ctrl_sig_0' is floating\n")
        # Case 3: Semantic Split (ë¶„ë¦¬ ëŒ€ìƒ)
        f.write("TIM-05: Path 'axi_read_data' setup violation\n")
        f.write("TIM-05: Path 'axi_write_data' setup violation\n")
        # Case 4: N-Tuple (Context)
        f.write("LINT-99: Port 'dft_scan' connects to 'nc_port'\n")
        f.write("LINT-99: Port 'dft_scan' connects to 'sys_clk'\n")
        f.write("--------------------------------\n")
        f.write("Info: End of Report\n")

    print(f"ğŸš€ Analyzing {dummy_file}...\n")

    # --- 1. íŒŒì¼ ì½ê¸° (Filter) ---
    reader = SubutaiLogReader(dummy_file)
    valid_lines = list(reader.stream_valid_lines())
    print(f"ğŸ“‹ Valid Lines: {len(valid_lines)} lines found (Filtered)\n")

    # --- 2. íŒŒì‹± (N-Tuple Extraction) ---
    parser = SubutaiParser()
    parsed_data = [parser.parse_line(line) for line in valid_lines]

    # --- 3. í´ëŸ¬ìŠ¤í„°ë§ (Logic Engine) ---
    clusterer = SubutaiClusterer()
    results = clusterer.run(parsed_data)

    # --- 4. ê²°ê³¼ ì¶œë ¥ ---
    print(json.dumps(results, indent=2))
    
    # (Clean up)
    if os.path.exists(dummy_file):
        os.remove(dummy_file)