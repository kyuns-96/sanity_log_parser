import os
import sys
import re
import json
import hashlib
import time
from collections import defaultdict

# ==============================================================================
# [Dependency Check]
# ==============================================================================
try:
    from sentence_transformers import SentenceTransformer
    from sklearn.cluster import DBSCAN
    import numpy as np
    AI_AVAILABLE = True
except ImportError:
    AI_AVAILABLE = False

# ==============================================================================
# 1. Template Manager (Rule File Loader)
# ==============================================================================
class RuleTemplateManager:
    def __init__(self, template_file):
        self.template_dict = {} # {Pure_Template_String : Rule_ID}
        self.var_pattern = re.compile(r"'(.*?)'")
        
        if template_file:
            print(f"ğŸ“‚ Loading Rule Templates from: {template_file}")
            self._load_templates(template_file)
        else:
            print("âš ï¸ No template file provided.")

    def _get_pure_template(self, text):
        """
        [í•µì‹¬ ë¡œì§] ë©”ì‹œì§€ì—ì„œ ë³€ìˆ˜ì™€ ìˆ«ìë¥¼ ì•ˆì „í•˜ê²Œ ë§ˆìŠ¤í‚¹
        1. ë³€ìˆ˜('...')ë¥¼ ë¨¼ì € <VAR>ë¡œ ì¹˜í™˜í•˜ì—¬ ë³€ìˆ˜ëª… ë‚´ë¶€ ë³´í˜¸
        2. ê·¸ í›„, ë‚¨ì€ í…ìŠ¤íŠ¸ì—ì„œ 'ë‹¨ì–´ ê²½ê³„ê°€ ìˆëŠ” ìˆ«ì'ë§Œ <NUM>ìœ¼ë¡œ ì¹˜í™˜
        """
        # 1. ë³€ìˆ˜ ì˜ì—­ ë³´í˜¸ (<VAR>)
        temp = self.var_pattern.sub("'<VAR>'", text)
        
        # 2. ë…ë¦½ëœ ìˆ«ìë§Œ ë§ˆìŠ¤í‚¹ (\bëŠ” ë‹¨ì–´ ê²½ê³„ë¥¼ ì˜ë¯¸)
        # ì˜ˆ: "Size 100" -> "Size <NUM>", "u_cpu_0" -> "u_cpu_0" (ë³€í™” ì—†ìŒ)
        temp = re.sub(r"\b\d+\b", "<NUM>", temp)
        
        return temp.strip()

    def _load_templates(self, file_path):
        if not os.path.exists(file_path):
            print(f"âŒ Template file not found: {file_path}")
            sys.exit(1)

        count = 0
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            for line in f:
                line = line.strip()
                # í—¤ë”ë‚˜ êµ¬ë¶„ì„  ê±´ë„ˆë›°ê¸°
                if not line or line.startswith(('-', 'Rule', 'Severity')): continue
                
                # íŒŒì‹±: Rule_ID ... Message
                # ê³µë°±ìœ¼ë¡œ 3ë²ˆë§Œ ìª¼ê°œì„œ ë§ˆì§€ë§‰ ë‚˜ë¨¸ì§€ë¥¼ Messageë¡œ ê°„ì£¼
                parts = line.split(maxsplit=3)
                if len(parts) < 4: continue
                
                rule_id = parts[0]
                message = parts[3]
                
                # ë¼ˆëŒ€ ì¶”ì¶œ ë° ë“±ë¡
                pure_temp = self._get_pure_template(message)
                self.template_dict[pure_temp] = rule_id
                count += 1
        
        print(f"âœ… Loaded {count} templates.")

    def get_rule_id(self, log_template):
        # í…œí”Œë¦¿ ì‚¬ì „ì— ìˆìœ¼ë©´ Rule ID ë°˜í™˜, ì—†ìœ¼ë©´ í•´ì‹œ ID ìƒì„±
        return self.template_dict.get(log_template, f"UNKNOWN_{hashlib.md5(log_template.encode()).hexdigest()[:6].upper()}")

# ==============================================================================
# 2. Parser
# ==============================================================================
class SubutaiParser:
    def __init__(self, template_manager):
        self.var_pattern = re.compile(r"'(.*?)'")
        self.tm = template_manager

    def parse_line(self, line):
        line = line.strip()
        if not line: return None
        
        if re.search(r'\b\d+\s+of\s+\d+\b', line):
            pass # ì˜ˆ: "3 of 5"
        else:
            return None
        
        line = " ".join(line.split()[4:]) # ì• 4ê°œ í† í° ì œê±°

        # 1. ë³€ìˆ˜ ì¶”ì¶œ (ìˆëŠ” ê·¸ëŒ€ë¡œ)
        variables = self.var_pattern.findall(line)
        var_tuple = tuple(variables) if variables else ("NO_VAR",)
        
        # 2. í…œí”Œë¦¿ ìƒì„± (ë§¤ë‹ˆì €ì™€ ë™ì¼í•œ ì•ˆì „ ë¡œì§ ì‚¬ìš©)
        template = self.tm._get_pure_template(line)
        
        # 3. Rule ID ë§¤ì¹­
        rule_id = self.tm.get_rule_id(template)
        
        return {
            "rule_id": rule_id,
            "variables": var_tuple,
            "template": template,
            "raw_log": line
        }

# ==============================================================================
# 3. Logic Clusterer
# ==============================================================================
class LogicClusterer:
    def get_logic_signature(self, var_tuple):
        if not var_tuple or var_tuple == ("NO_VAR",): return "NO_VAR"
        
        # ê·¸ë£¹í•‘ì„ ìœ„í•´ ë³€ìˆ˜ ê²½ë¡œ ë‚´ì˜ ìˆ«ìëŠ” ì—¬ê¸°ì„œ ë§ˆìŠ¤í‚¹ (*)
        # u_cpu_0 -> u_cpu_*
        sigs = [re.sub(r"\d+", "*", str(v)) for v in var_tuple]
        return " / ".join(sigs)

    def run(self, parsed_logs):
        groups = defaultdict(list)
        
        for p in parsed_logs:
            # ê·¸ë£¹í•‘ í‚¤: Rule ID + ë³€ìˆ˜ íŒ¨í„´ + ë¬¸ì¥ ë¼ˆëŒ€
            sig = self.get_logic_signature(p['variables'])
            key = (p['rule_id'], sig, p['template'])
            groups[key].append(p)

        results = []
        for (rule_id, sig, temp), members in groups.items():
            results.append({
                "rule_id": rule_id,
                "pattern": sig,
                "template": temp,
                "count": len(members),
                "members": members
            })
        
        # Count ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        results.sort(key=lambda x: x['count'], reverse=True)
        return results

# ==============================================================================
# 4. AI Clusterer
# ==============================================================================
class AIClusterer:
    def __init__(self, model_path='all-MiniLM-L6-v2'):
        if AI_AVAILABLE:
            print(f"â³ Loading AI Model ({model_path})...")
            try:
                self.model = SentenceTransformer(model_path)
            except Exception as e:
                print(f"âš ï¸ Model load failed: {e}")
                global AI_AVAILABLE
                AI_AVAILABLE = False

    def run(self, logic_groups):
        if not AI_AVAILABLE or not logic_groups: return logic_groups

        print(f"ğŸ¤– AI analyzing {len(logic_groups)} logic groups...")
        
        # ì„ë² ë”© ì…ë ¥: í…œí”Œë¦¿(ë¬¸ì¥ì˜ë¯¸) + íŒ¨í„´(ë³€ìˆ˜êµ¬ì¡°)
        embedding_inputs = [f"{g['template']} {g['pattern']}" for g in logic_groups]
        embeddings = self.model.encode(embedding_inputs, batch_size=128, show_progress_bar=False)
        
        # DBSCAN: ì½”ì‚¬ì¸ ê±°ë¦¬ 0.2 ì´ë‚´ (ìœ ì‚¬ë„ 80% ì´ìƒ)
        clustering = DBSCAN(eps=0.2, min_samples=1, metric='cosine').fit(embeddings)
        labels = clustering.labels_

        ai_grouped = defaultdict(lambda: {
            "total_count": 0, "logic_subgroups": []
        })

        for label, logic_group in zip(labels, logic_groups):
            # Rule IDê°€ ë‹¤ë¥´ë©´ ì„ì´ì§€ ì•Šë„ë¡ í‚¤ ì„¤ì •
            cluster_key = f"{logic_group['rule_id']}_SG_{label}"
            
            group_data = ai_grouped[cluster_key]
            group_data["total_count"] += logic_group['count']
            group_data["logic_subgroups"].append(logic_group)

        final_output = []
        for key, data in ai_grouped.items():
            # ê°€ì¥ ë¹ˆë„ ë†’ì€ ë¡œì§ ê·¸ë£¹ì„ ëŒ€í‘œë¡œ ì„ ì •
            main = max(data["logic_subgroups"], key=lambda x: x['count'])
            
            final_output.append({
                "super_group_id": key,
                "rule_id": main['rule_id'],
                "representative_template": main['template'],
                "representative_pattern": main['pattern'],
                "total_count": data["total_count"],
                "logic_subgroups": data["logic_subgroups"]
            })
        
        final_output.sort(key=lambda x: x['total_count'], reverse=True)
        return final_output

# ==============================================================================
# 5. Main Execution
# ==============================================================================
if __name__ == "__main__":
    if len(sys.argv) < 3:
        print("\nâŒ Usage: python subutai_reviewer.py <LOG_FILE> <TEMPLATE_FILE>")
        print("   Ex: python subutai_reviewer.py run.log rules.txt\n")
        sys.exit(1)

    log_file = sys.argv[1]
    rule_file = sys.argv[2]

    # 1. í…œí”Œë¦¿ ë¡œë“œ
    tm = RuleTemplateManager(rule_file)
    
    # 2. ë¡œê·¸ íŒŒì¼ ì½ê¸° & íŒŒì‹±
    print(f"ğŸ“‚ Parsing Log File: {log_file}")
    parser = SubutaiParser(tm)
    parsed_logs = []
    
    if os.path.exists(log_file):
        with open(log_file, 'r', encoding='utf-8', errors='ignore') as f:
            for line in f:
                # í—¤ë”ë‚˜ ê³µë°± ë¼ì¸ í•„í„°ë§ (ì‚¬ìš©ì í™˜ê²½ì— ë§ì¶° ì¡°ì • ê°€ëŠ¥)
                stripped = line.strip()
                if not stripped or stripped.startswith(('-', '=', 'Rule', 'Severity')):
                    continue
                
                res = parser.parse_line(stripped)
                if res: parsed_logs.append(res)
    else:
        print(f"âŒ Log file not found: {log_file}")
        sys.exit(1)

    print(f"âœ… Parsed {len(parsed_logs)} lines.")

    # 3. Stage 1: Logic Clustering
    logic_engine = LogicClusterer()
    logic_results = logic_engine.run(parsed_logs)

    print("\n" + "="*80)
    print(f"ğŸ“Š STAGE 1 REPORT: Logic Clustering ({len(logic_results)} Groups)")
    print("="*80)
    for i, g in enumerate(logic_results[:10]):
        print(f"L{i+1:02d}. [{g['rule_id']}] Count: {g['count']:,}")
        print(f"     Template: {g['template']}")
        print(f"     Pattern : {g['pattern']}")
        
        # ì‹¤ì œ ë³€ìˆ˜ ìƒ˜í”Œ í™•ì¸ (ë³€ìˆ˜ëª… í›¼ì† ì—¬ë¶€ ì²´í¬ìš©)
        sample_vars = list(set(["/".join(m['variables']) for m in g['members'] if m['variables'] != ("NO_VAR",)]))
        if sample_vars:
            print(f"     Samples : {sample_vars[:2]}")
        print("-" * 60)

    # 4. Stage 2: AI Clustering
    if AI_AVAILABLE:
        ai_engine = AIClusterer() # ëª¨ë¸ ê²½ë¡œëŠ” í•„ìš”ì‹œ ìˆ˜ì • (ì˜ˆ: './model_folder')
        final_results = ai_engine.run(logic_results)

        print("\n" + "="*80)
        print(f"ğŸš€ STAGE 2 REPORT: AI Semantic Merge ({len(final_results)} Super Groups)")
        print("="*80)
        for i, g in enumerate(final_results[:15]):
            print(f"A{i+1:02d}. [{g['rule_id']}] Count: {g['total_count']:,}")
            print(f"     Rep.Template: {g['representative_template']}")
            print(f"     Rep.Pattern : {g['representative_pattern']}")
            
            if len(g['logic_subgroups']) > 1:
                print(f"     >>> Merged {len(g['logic_subgroups'])} variants:")
                # ë³‘í•©ëœ í•˜ìœ„ íŒ¨í„´ë“¤ ë³´ì—¬ì£¼ê¸°
                sub_list = sorted(g['logic_subgroups'], key=lambda x: x['count'], reverse=True)
                for sub in sub_list[:3]:
                    print(f"         - {sub['pattern']} (cnt: {sub['count']})")
                if len(sub_list) > 3:
                    print(f"         - ... and {len(sub_list)-3} more")
            print("-" * 60)
    else:
        print("\nâš ï¸ AI Library not found. Skipping Stage 2.")
